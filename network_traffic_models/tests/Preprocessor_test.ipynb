{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fa72bf1",
   "metadata": {},
   "source": [
    "## Testing the Preprocessor Class\n",
    "\n",
    "In this notebook, we will test our `Preprocessor` class to ensure it functions correctly with network traffic data. The `Preprocessor` class is designed to preprocess network traffic data and prepare it for model prediction. Here are the steps we will follow:\n",
    "\n",
    "1. **Set up the environment**: Import necessary libraries and add the project root to the Python path\n",
    "2. **Load a sample dataset**: Create or load some sample network traffic data\n",
    "3. **Initialize Preprocessor**: Create an instance of the `Preprocessor` class \n",
    "4. **Preprocess Data**: Apply preprocessing steps to prepare the data for the models\n",
    "5. **Verify Results**: Check that preprocessed data has the right format and features\n",
    "\n",
    "Let's start by setting up the environment and importing the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07856336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: c:\\Users\\HAMZA\\Desktop\\smartshield\\MLEngine-main\\MLEngine-main\\network_traffic_anomaly_detection\n",
      "Successfully imported Preprocessor class\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Add the project root to the Python path\n",
    "project_root = os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), \"..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# Import our preprocessor\n",
    "from src.data.preprocessor.preprocessor import Preprocessor\n",
    "# Import the log_features from feature_engineering module\n",
    "from src.features.feature_engineering import log_features\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(\"Successfully imported Preprocessor class\")\n",
    "print(f\"Log features to be transformed: {log_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1a2413",
   "metadata": {},
   "source": [
    "## Generate Sample Data\n",
    "\n",
    "Let's create a small sample dataset of network traffic data that we can use to test our preprocessor. We'll create a mix of normal and attack traffic samples with realistic values for key features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ff1d121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 10 sample records\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>...</th>\n",
       "      <th>sload</th>\n",
       "      <th>dload</th>\n",
       "      <th>sloss</th>\n",
       "      <th>dloss</th>\n",
       "      <th>sinpkt</th>\n",
       "      <th>dinpkt</th>\n",
       "      <th>sjit</th>\n",
       "      <th>djit</th>\n",
       "      <th>smean</th>\n",
       "      <th>dmean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.938536</td>\n",
       "      <td>ospf</td>\n",
       "      <td>smtp</td>\n",
       "      <td>CON</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>4043</td>\n",
       "      <td>4397</td>\n",
       "      <td>82</td>\n",
       "      <td>94</td>\n",
       "      <td>...</td>\n",
       "      <td>1.897377</td>\n",
       "      <td>3.565321</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.024646</td>\n",
       "      <td>0.043474</td>\n",
       "      <td>0.008167</td>\n",
       "      <td>0.037557</td>\n",
       "      <td>538</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.020243</td>\n",
       "      <td>udp</td>\n",
       "      <td>-</td>\n",
       "      <td>REQ</td>\n",
       "      <td>89</td>\n",
       "      <td>71</td>\n",
       "      <td>7655</td>\n",
       "      <td>1095</td>\n",
       "      <td>53</td>\n",
       "      <td>118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.596839</td>\n",
       "      <td>1.889905</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.053873</td>\n",
       "      <td>0.036353</td>\n",
       "      <td>0.005172</td>\n",
       "      <td>0.005294</td>\n",
       "      <td>302</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.633491</td>\n",
       "      <td>arp</td>\n",
       "      <td>-</td>\n",
       "      <td>REQ</td>\n",
       "      <td>60</td>\n",
       "      <td>44</td>\n",
       "      <td>3173</td>\n",
       "      <td>7729</td>\n",
       "      <td>24</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100274</td>\n",
       "      <td>1.279162</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.214798</td>\n",
       "      <td>0.017991</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>283</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.825885</td>\n",
       "      <td>udp</td>\n",
       "      <td>http</td>\n",
       "      <td>INT</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>1121</td>\n",
       "      <td>9567</td>\n",
       "      <td>26</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463335</td>\n",
       "      <td>0.269168</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039207</td>\n",
       "      <td>0.076376</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.004232</td>\n",
       "      <td>222</td>\n",
       "      <td>851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.339250</td>\n",
       "      <td>arp</td>\n",
       "      <td>http</td>\n",
       "      <td>CON</td>\n",
       "      <td>9</td>\n",
       "      <td>47</td>\n",
       "      <td>3943</td>\n",
       "      <td>1116</td>\n",
       "      <td>89</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>1.105157</td>\n",
       "      <td>0.295806</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013021</td>\n",
       "      <td>0.066326</td>\n",
       "      <td>0.002835</td>\n",
       "      <td>0.010061</td>\n",
       "      <td>500</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        dur proto service state  spkts  dpkts  sbytes  dbytes  rate  sttl  \\\n",
       "0  0.938536  ospf    smtp   CON      4     60    4043    4397    82    94   \n",
       "1  6.020243   udp       -   REQ     89     71    7655    1095    53   118   \n",
       "2  2.633491   arp       -   REQ     60     44    3173    7729    24   100   \n",
       "3  1.825885   udp    http   INT     14      8    1121    9567    26    38   \n",
       "4  0.339250   arp    http   CON      9     47    3943    1116    89   117   \n",
       "\n",
       "   ...     sload     dload  sloss  dloss    sinpkt    dinpkt      sjit  \\\n",
       "0  ...  1.897377  3.565321      0      2  0.024646  0.043474  0.008167   \n",
       "1  ...  0.596839  1.889905      3      2  0.053873  0.036353  0.005172   \n",
       "2  ...  0.100274  1.279162      4      3  0.214798  0.017991  0.000671   \n",
       "3  ...  0.463335  0.269168      3      1  0.039207  0.076376  0.002929   \n",
       "4  ...  1.105157  0.295806      4      1  0.013021  0.066326  0.002835   \n",
       "\n",
       "       djit  smean  dmean  \n",
       "0  0.037557    538    709  \n",
       "1  0.005294    302    297  \n",
       "2  0.000336    283    610  \n",
       "3  0.004232    222    851  \n",
       "4  0.010061    500    243  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_sample_data(n_samples=10, random_state=42):\n",
    "    \"\"\"Generate synthetic network traffic data for testing\"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Create sample data with the most essential features\n",
    "    synthetic_data = {\n",
    "        'dur': np.random.exponential(2, n_samples),\n",
    "        'proto': np.random.choice(['tcp', 'udp', 'icmp', 'arp', 'ospf'], n_samples),\n",
    "        'service': np.random.choice(['-', 'dns', 'http', 'smtp', 'ftp', 'ssh'], n_samples),\n",
    "        'state': np.random.choice(['INT', 'FIN', 'CON', 'REQ', 'RST'], n_samples),\n",
    "        'spkts': np.random.randint(1, 100, n_samples),\n",
    "        'dpkts': np.random.randint(1, 100, n_samples),\n",
    "        'sbytes': np.random.randint(100, 10000, n_samples),\n",
    "        'dbytes': np.random.randint(100, 10000, n_samples),\n",
    "        'rate': np.random.randint(1, 100, n_samples),\n",
    "        'sttl': np.random.randint(30, 255, n_samples),\n",
    "        'dttl': np.random.randint(30, 255, n_samples),\n",
    "        'sload': np.random.exponential(1, n_samples),\n",
    "        'dload': np.random.exponential(1, n_samples),\n",
    "        'sloss': np.random.randint(0, 5, n_samples),\n",
    "        'dloss': np.random.randint(0, 5, n_samples),\n",
    "        'sinpkt': np.random.exponential(0.1, n_samples),\n",
    "        'dinpkt': np.random.exponential(0.1, n_samples),\n",
    "        'sjit': np.random.exponential(0.01, n_samples),\n",
    "        'djit': np.random.exponential(0.01, n_samples),\n",
    "        'smean': np.random.randint(100, 1000, n_samples),\n",
    "        'dmean': np.random.randint(100, 1000, n_samples),\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame(synthetic_data)\n",
    "\n",
    "# Generate 10 sample records\n",
    "sample_data = generate_sample_data(n_samples=10)\n",
    "\n",
    "# Display the samples\n",
    "print(f\"Generated {len(sample_data)} sample records\")\n",
    "sample_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d924af0",
   "metadata": {},
   "source": [
    "## Save Sample Data\n",
    "\n",
    "Let's save our sample data to a parquet file so we can reuse it in our other test notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88cc4bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample data to data/sample_traffic_data.parquet\n"
     ]
    }
   ],
   "source": [
    "# Create the tests directory if it doesn't exist\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Save the sample data to a parquet file\n",
    "sample_path = \"data/sample_traffic_data.parquet\"\n",
    "sample_data.to_parquet(sample_path, index=False)\n",
    "\n",
    "print(f\"Saved sample data to {sample_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf6d0a0",
   "metadata": {},
   "source": [
    "## Initialize the Preprocessor\n",
    "\n",
    "Now we'll create an instance of our `Preprocessor` class. For this test, we need to provide a path to a model file, though we won't be using the model itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1118aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at c:\\Users\\HAMZA\\Desktop\\smartshield\\MLEngine-main\\MLEngine-main\\network_traffic_anomaly_detection\\models\\detection_model.cbm\n",
      "Model loaded with 26 features\n",
      "Successfully created Preprocessor instance\n"
     ]
    }
   ],
   "source": [
    "# Use a dummy model path for testing\n",
    "model_path = os.path.join(project_root, \"models\", \"detection_model.cbm\")\n",
    "\n",
    "# Check if the model file exists\n",
    "if not os.path.exists(model_path):\n",
    "    print(f\"Model file not found: {model_path}\")\n",
    "    print(\"Running setup_models.py to create dummy models...\")\n",
    "    \n",
    "    # Change directory to project root\n",
    "    os.chdir(project_root)\n",
    "    \n",
    "    # Run setup_models.py to create dummy models\n",
    "    from setup_models import setup_models\n",
    "    setup_models()\n",
    "    \n",
    "    print(\"Dummy models created successfully\")\n",
    "else:\n",
    "    print(f\"Found model file at {model_path}\")\n",
    "\n",
    "# Create the preprocessor instance\n",
    "preprocessor = Preprocessor(model_path)\n",
    "\n",
    "# Add log_features attribute to the preprocessor for testing\n",
    "# This wouldn't be needed in production as it should be in the class\n",
    "preprocessor.log_features = log_features\n",
    "\n",
    "print(\"Successfully created Preprocessor instance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f014363",
   "metadata": {},
   "source": [
    "## Test Feature Engineering\n",
    "\n",
    "Let's test the feature engineering functionality of our preprocessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "797b6aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New features created:\n",
      "- Time_per_Process\n",
      "- Network_Activity_Rate\n",
      "- Ratio_of_Data_Flow\n",
      "- Speed_of_Operations_to_Data_Bytes\n",
      "- Ratio_of_Packet_Flow\n",
      "- Network_Usage\n",
      "- Total_Page_Errors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>...</th>\n",
       "      <th>djit</th>\n",
       "      <th>smean</th>\n",
       "      <th>dmean</th>\n",
       "      <th>Speed_of_Operations_to_Data_Bytes</th>\n",
       "      <th>Time_per_Process</th>\n",
       "      <th>Ratio_of_Data_Flow</th>\n",
       "      <th>Ratio_of_Packet_Flow</th>\n",
       "      <th>Total_Page_Errors</th>\n",
       "      <th>Network_Usage</th>\n",
       "      <th>Network_Activity_Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.938536</td>\n",
       "      <td>ospf</td>\n",
       "      <td>smtp</td>\n",
       "      <td>CON</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>4043</td>\n",
       "      <td>4397</td>\n",
       "      <td>82</td>\n",
       "      <td>94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037557</td>\n",
       "      <td>538</td>\n",
       "      <td>709</td>\n",
       "      <td>0.652060</td>\n",
       "      <td>0.210775</td>\n",
       "      <td>0.735995</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.040856</td>\n",
       "      <td>4.174387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.020243</td>\n",
       "      <td>udp</td>\n",
       "      <td>-</td>\n",
       "      <td>REQ</td>\n",
       "      <td>89</td>\n",
       "      <td>71</td>\n",
       "      <td>7655</td>\n",
       "      <td>1095</td>\n",
       "      <td>53</td>\n",
       "      <td>118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005294</td>\n",
       "      <td>302</td>\n",
       "      <td>297</td>\n",
       "      <td>2.078299</td>\n",
       "      <td>0.065454</td>\n",
       "      <td>0.133695</td>\n",
       "      <td>0.586537</td>\n",
       "      <td>2.947630</td>\n",
       "      <td>9.076923</td>\n",
       "      <td>5.081404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.633491</td>\n",
       "      <td>arp</td>\n",
       "      <td>-</td>\n",
       "      <td>REQ</td>\n",
       "      <td>60</td>\n",
       "      <td>44</td>\n",
       "      <td>3173</td>\n",
       "      <td>7729</td>\n",
       "      <td>24</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>283</td>\n",
       "      <td>610</td>\n",
       "      <td>0.343967</td>\n",
       "      <td>0.042956</td>\n",
       "      <td>1.234269</td>\n",
       "      <td>0.550046</td>\n",
       "      <td>2.445296</td>\n",
       "      <td>9.296793</td>\n",
       "      <td>4.653960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.825885</td>\n",
       "      <td>udp</td>\n",
       "      <td>http</td>\n",
       "      <td>INT</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>1121</td>\n",
       "      <td>9567</td>\n",
       "      <td>26</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004232</td>\n",
       "      <td>222</td>\n",
       "      <td>851</td>\n",
       "      <td>0.110802</td>\n",
       "      <td>0.122590</td>\n",
       "      <td>2.254900</td>\n",
       "      <td>0.451985</td>\n",
       "      <td>1.868359</td>\n",
       "      <td>9.276970</td>\n",
       "      <td>3.135494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.339250</td>\n",
       "      <td>arp</td>\n",
       "      <td>http</td>\n",
       "      <td>CON</td>\n",
       "      <td>9</td>\n",
       "      <td>47</td>\n",
       "      <td>3943</td>\n",
       "      <td>1116</td>\n",
       "      <td>89</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010061</td>\n",
       "      <td>500</td>\n",
       "      <td>243</td>\n",
       "      <td>1.511418</td>\n",
       "      <td>0.037001</td>\n",
       "      <td>0.249227</td>\n",
       "      <td>1.828127</td>\n",
       "      <td>0.857389</td>\n",
       "      <td>8.529122</td>\n",
       "      <td>4.043051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        dur proto service state  spkts  dpkts  sbytes  dbytes  rate  sttl  \\\n",
       "0  0.938536  ospf    smtp   CON      4     60    4043    4397    82    94   \n",
       "1  6.020243   udp       -   REQ     89     71    7655    1095    53   118   \n",
       "2  2.633491   arp       -   REQ     60     44    3173    7729    24   100   \n",
       "3  1.825885   udp    http   INT     14      8    1121    9567    26    38   \n",
       "4  0.339250   arp    http   CON      9     47    3943    1116    89   117   \n",
       "\n",
       "   ...      djit  smean  dmean  Speed_of_Operations_to_Data_Bytes  \\\n",
       "0  ...  0.037557    538    709                           0.652060   \n",
       "1  ...  0.005294    302    297                           2.078299   \n",
       "2  ...  0.000336    283    610                           0.343967   \n",
       "3  ...  0.004232    222    851                           0.110802   \n",
       "4  ...  0.010061    500    243                           1.511418   \n",
       "\n",
       "   Time_per_Process  Ratio_of_Data_Flow  Ratio_of_Packet_Flow  \\\n",
       "0          0.210775            0.735995              2.772589   \n",
       "1          0.065454            0.133695              0.586537   \n",
       "2          0.042956            1.234269              0.550046   \n",
       "3          0.122590            2.254900              0.451985   \n",
       "4          0.037001            0.249227              1.828127   \n",
       "\n",
       "   Total_Page_Errors  Network_Usage  Network_Activity_Rate  \n",
       "0           0.000000       9.040856               4.174387  \n",
       "1           2.947630       9.076923               5.081404  \n",
       "2           2.445296       9.296793               4.653960  \n",
       "3           1.868359       9.276970               3.135494  \n",
       "4           0.857389       8.529122               4.043051  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply feature engineering to the sample data\n",
    "engineered_data = preprocessor.feature_engineering(sample_data)\n",
    "\n",
    "# Check what new features were created\n",
    "original_columns = set(sample_data.columns)\n",
    "new_columns = set(engineered_data.columns) - original_columns\n",
    "\n",
    "print(\"New features created:\")\n",
    "for col in new_columns:\n",
    "    print(f\"- {col}\")\n",
    "\n",
    "# Display the engineered data\n",
    "engineered_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8edaf9",
   "metadata": {},
   "source": [
    "## Test Categorical Feature Transformation\n",
    "\n",
    "Now let's test the categorical feature transformation functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a88fc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original categorical distributions:\n",
      "\n",
      "proto distribution:\n",
      "proto\n",
      "ospf    3\n",
      "udp     3\n",
      "arp     3\n",
      "tcp     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "service distribution:\n",
      "service\n",
      "smtp    3\n",
      "-       2\n",
      "http    2\n",
      "ssh     2\n",
      "dns     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "state distribution:\n",
      "state\n",
      "CON    3\n",
      "REQ    2\n",
      "INT    2\n",
      "RST    2\n",
      "FIN    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Transformed categorical distributions:\n",
      "\n",
      "proto distribution:\n",
      "proto\n",
      "ospf    3\n",
      "udp     3\n",
      "arp     3\n",
      "tcp     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "service distribution:\n",
      "service\n",
      "smtp    3\n",
      "-       2\n",
      "http    2\n",
      "ssh     2\n",
      "dns     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "state distribution:\n",
      "state\n",
      "CON    3\n",
      "REQ    2\n",
      "INT    2\n",
      "RST    2\n",
      "FIN    1\n",
      "Name: count, dtype: int64\n",
      "Invalid values found in proto: ['ospf' 'udp' 'arp' 'tcp']\n",
      "All values in service are valid\n",
      "All values in state are valid\n"
     ]
    }
   ],
   "source": [
    "# Examine categorical distributions before transformation\n",
    "print(\"Original categorical distributions:\")\n",
    "for cat_feature in preprocessor.categorical_features:\n",
    "    if cat_feature in sample_data.columns:\n",
    "        print(f\"\\n{cat_feature} distribution:\")\n",
    "        print(sample_data[cat_feature].value_counts())\n",
    "\n",
    "# Apply categorical transformations\n",
    "transformed_data = preprocessor.transform_categories(sample_data)\n",
    "\n",
    "# Examine categorical distributions after transformation\n",
    "print(\"\\nTransformed categorical distributions:\")\n",
    "for cat_feature in preprocessor.categorical_features:\n",
    "    if cat_feature in transformed_data.columns:\n",
    "        print(f\"\\n{cat_feature} distribution:\")\n",
    "        print(transformed_data[cat_feature].value_counts())\n",
    "\n",
    "# Check for any non-standard values (should all be in top categories or '-')\n",
    "for cat_feature in preprocessor.categorical_features:\n",
    "    if cat_feature in transformed_data.columns:\n",
    "        valid_categories = getattr(preprocessor, f\"top_{cat_feature}_categories\", []) + ['-']\n",
    "        invalid_values = transformed_data[~transformed_data[cat_feature].isin(valid_categories)][cat_feature].unique()\n",
    "        if len(invalid_values) > 0:\n",
    "            print(f\"Invalid values found in {cat_feature}: {invalid_values}\")\n",
    "        else:\n",
    "            print(f\"All values in {cat_feature} are valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a933c0a",
   "metadata": {},
   "source": [
    "## Test Log Feature Creation\n",
    "\n",
    "Let's test the log transformation of numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a573d933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics before log transformation:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Preprocessor' object has no attribute 'log_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Get summary statistics before log transformation\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStatistics before log transformation:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpreprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_features\u001b[49m:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m sample_data\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeature\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: min=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_data[feature]\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, max=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_data[feature]\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, mean=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_data[feature]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Preprocessor' object has no attribute 'log_features'"
     ]
    }
   ],
   "source": [
    "# Get summary statistics before log transformation\n",
    "print(\"Statistics before log transformation:\")\n",
    "for feature in log_features:  # Using log_features directly\n",
    "    if feature in sample_data.columns:\n",
    "        print(f\"{feature}: min={sample_data[feature].min():.2f}, max={sample_data[feature].max():.2f}, mean={sample_data[feature].mean():.2f}\")\n",
    "\n",
    "# Apply log transformation\n",
    "log_transformed_data = preprocessor.create_log1p_features(sample_data)\n",
    "\n",
    "# Get summary statistics after log transformation\n",
    "print(\"\\nStatistics after log transformation:\")\n",
    "for feature in log_features:  # Using log_features directly\n",
    "    if feature in log_transformed_data.columns:\n",
    "        print(f\"{feature}: min={log_transformed_data[feature].min():.2f}, max={log_transformed_data[feature].max():.2f}, mean={log_transformed_data[feature].mean():.2f}\")\n",
    "\n",
    "# Check if values are indeed logged (should be smaller than original)\n",
    "for feature in log_features:  # Using log_features directly\n",
    "    if feature in sample_data.columns and feature in log_transformed_data.columns:\n",
    "        if log_transformed_data[feature].max() > sample_data[feature].max():\n",
    "            print(f\"Warning: Log transformation didn't reduce the maximum value for {feature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed09869b",
   "metadata": {},
   "source": [
    "## Test Complete Preprocessing Pipeline\n",
    "\n",
    "Now let's test the complete preprocessing pipeline, which combines all the individual steps we've tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7960e006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the complete preprocessing pipeline\n",
    "preprocessed_data = preprocessor.preprocess(sample_data)\n",
    "\n",
    "# Display the processed data\n",
    "print(f\"Preprocessed data shape: {preprocessed_data.shape}\")\n",
    "print(f\"Columns in preprocessed data: {len(preprocessed_data.columns)}\")\n",
    "print(f\"First 5 columns: {list(preprocessed_data.columns)[:5]}\")\n",
    "\n",
    "# Check that all expected columns are present\n",
    "if preprocessor.feature_names is not None:\n",
    "    missing_columns = set(preprocessor.feature_names) - set(preprocessed_data.columns)\n",
    "    extra_columns = set(preprocessed_data.columns) - set(preprocessor.feature_names)\n",
    "    \n",
    "    if missing_columns:\n",
    "        print(f\"Warning: {len(missing_columns)} expected columns are missing\")\n",
    "        print(f\"First few missing columns: {list(missing_columns)[:5]}\")\n",
    "    else:\n",
    "        print(\"All expected columns are present\")\n",
    "        \n",
    "    if extra_columns:\n",
    "        print(f\"Warning: {len(extra_columns)} unexpected columns are present\")\n",
    "        print(f\"First few extra columns: {list(extra_columns)[:5]}\")\n",
    "    else:\n",
    "        print(\"No unexpected columns are present\")\n",
    "        \n",
    "# Display the first few rows of preprocessed data\n",
    "preprocessed_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39792c51",
   "metadata": {},
   "source": [
    "## Test Pool Creation\n",
    "\n",
    "Finally, let's test the creation of a CatBoost Pool object from our preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df9e467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pool from the preprocessed data\n",
    "try:\n",
    "    pool = preprocessor.create_pool(preprocessed_data)\n",
    "    print(f\"Successfully created CatBoost Pool with {pool.shape[0]} rows and {pool.shape[1]} columns\")\n",
    "    \n",
    "    # Check if categorical features were correctly specified\n",
    "    if hasattr(pool, 'get_cat_feature_indices'):\n",
    "        cat_indices = pool.get_cat_feature_indices()\n",
    "        print(f\"Pool has {len(cat_indices)} categorical feature indices: {cat_indices}\")\n",
    "    else:\n",
    "        print(\"Pool doesn't provide categorical feature indices\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating CatBoost Pool: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93785d9e",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We have successfully tested the `Preprocessor` class and verified that:\n",
    "\n",
    "1. It can generate engineered features correctly\n",
    "2. It properly transforms categorical features by grouping rare categories\n",
    "3. It applies log transformations to selected numerical features\n",
    "4. The complete preprocessing pipeline produces data with the expected format\n",
    "5. It can create a CatBoost Pool object for model training/prediction\n",
    "\n",
    "The preprocessor is working as expected and is ready for use with our models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
