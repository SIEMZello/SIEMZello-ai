{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c08ddad5",
   "metadata": {},
   "source": [
    "## Testing the DetectionModel Class\n",
    "\n",
    "In this notebook, we will test our `DetectionModel` class to ensure it correctly classifies network traffic as normal or attack. The steps involved in this process are as follows:\n",
    "\n",
    "1. **Set up the environment**: Import necessary libraries and add the project root to the Python path\n",
    "2. **Load sample data**: Use the sample data we created in the Preprocessor test\n",
    "3. **Initialize the model**: Create an instance of the `DetectionModel` class\n",
    "4. **Generate predictions**: Use the model to classify the sample network traffic\n",
    "5. **Analyze the results**: Verify the model provides sensible predictions and probabilities\n",
    "\n",
    "Let's start by setting up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d9be9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Add the project root to the Python path\n",
    "project_root = os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), \"..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# Import our detection model\n",
    "from src.models.detection_model import DetectionModel\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(\"Successfully imported DetectionModel class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169e921d",
   "metadata": {},
   "source": [
    "## Load Sample Data\n",
    "\n",
    "We'll load the sample data we created and saved in the Preprocessor test notebook. If the file doesn't exist, we'll generate new sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1e338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to sample data\n",
    "sample_path = \"data/sample_traffic_data.parquet\"\n",
    "\n",
    "# Check if the sample data file exists\n",
    "if os.path.exists(sample_path):\n",
    "    # Load the sample data\n",
    "    sample_data = pd.read_parquet(sample_path)\n",
    "    print(f\"Loaded {len(sample_data)} sample records from {sample_path}\")\n",
    "else:\n",
    "    print(f\"Sample data file {sample_path} not found. Generating new sample data...\")\n",
    "    \n",
    "    # Define function to generate sample data\n",
    "    def generate_sample_data(n_samples=10, random_state=42):\n",
    "        \"\"\"Generate synthetic network traffic data for testing\"\"\"\n",
    "        np.random.seed(random_state)\n",
    "        \n",
    "        synthetic_data = {\n",
    "            'dur': np.random.exponential(2, n_samples),\n",
    "            'proto': np.random.choice(['tcp', 'udp', 'icmp', 'arp', 'ospf'], n_samples),\n",
    "            'service': np.random.choice(['-', 'dns', 'http', 'smtp', 'ftp', 'ssh'], n_samples),\n",
    "            'state': np.random.choice(['INT', 'FIN', 'CON', 'REQ', 'RST'], n_samples),\n",
    "            'spkts': np.random.randint(1, 100, n_samples),\n",
    "            'dpkts': np.random.randint(1, 100, n_samples),\n",
    "            'sbytes': np.random.randint(100, 10000, n_samples),\n",
    "            'dbytes': np.random.randint(100, 10000, n_samples),\n",
    "            'rate': np.random.randint(1, 100, n_samples),\n",
    "            'sttl': np.random.randint(30, 255, n_samples),\n",
    "            'dttl': np.random.randint(30, 255, n_samples),\n",
    "            'sload': np.random.exponential(1, n_samples),\n",
    "            'dload': np.random.exponential(1, n_samples),\n",
    "            'sloss': np.random.randint(0, 5, n_samples),\n",
    "            'dloss': np.random.randint(0, 5, n_samples),\n",
    "            'sinpkt': np.random.exponential(0.1, n_samples),\n",
    "            'dinpkt': np.random.exponential(0.1, n_samples),\n",
    "            'sjit': np.random.exponential(0.01, n_samples),\n",
    "            'djit': np.random.exponential(0.01, n_samples),\n",
    "            'smean': np.random.randint(100, 1000, n_samples),\n",
    "            'dmean': np.random.randint(100, 1000, n_samples),\n",
    "        }\n",
    "        \n",
    "        # Create DataFrame\n",
    "        return pd.DataFrame(synthetic_data)\n",
    "    \n",
    "    # Generate sample data\n",
    "    sample_data = generate_sample_data(n_samples=10)\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "    \n",
    "    # Save the sample data\n",
    "    sample_data.to_parquet(sample_path, index=False)\n",
    "    print(f\"Generated and saved {len(sample_data)} sample records to {sample_path}\")\n",
    "\n",
    "# Display the first few rows\n",
    "sample_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa7d3df",
   "metadata": {},
   "source": [
    "## Initialize and Test the DetectionModel\n",
    "\n",
    "Now we'll create an instance of our `DetectionModel` class and use it to classify the sample network traffic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51aa448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we need to run setup_models.py to create dummy models\n",
    "model_path = os.path.join(project_root, \"models\", \"detection_model.cbm\")\n",
    "if not os.path.exists(model_path):\n",
    "    print(f\"Model file not found: {model_path}\")\n",
    "    print(\"Running setup_models.py to create dummy models...\")\n",
    "    \n",
    "    # Change directory to project root\n",
    "    os.chdir(project_root)\n",
    "    \n",
    "    # Run setup_models.py to create dummy models\n",
    "    from setup_models import setup_models\n",
    "    setup_models()\n",
    "    \n",
    "    print(\"Dummy models created successfully\")\n",
    "else:\n",
    "    print(f\"Found model file at {model_path}\")\n",
    "\n",
    "# Initialize the detection model\n",
    "detection_model = DetectionModel()\n",
    "\n",
    "print(\"Successfully initialized DetectionModel\")\n",
    "print(f\"Using model file: {detection_model.model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a7098a",
   "metadata": {},
   "source": [
    "## Generate Binary Predictions\n",
    "\n",
    "Let's use the model to classify the sample network traffic as either normal (0) or attack (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35043976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate binary predictions\n",
    "try:\n",
    "    # Get binary predictions (0: normal, 1: attack)\n",
    "    predictions = detection_model.predict(sample_data)\n",
    "    \n",
    "    # Get prediction probabilities\n",
    "    probabilities = detection_model.predict_proba(sample_data)\n",
    "    \n",
    "    # Add predictions and probabilities to the sample data\n",
    "    results = sample_data.copy()\n",
    "    results['predicted_label'] = predictions\n",
    "    results['attack_probability'] = probabilities\n",
    "    \n",
    "    # Display prediction counts\n",
    "    prediction_counts = pd.Series(predictions).value_counts()\n",
    "    print(\"Prediction counts:\")\n",
    "    for label, count in prediction_counts.items():\n",
    "        print(f\"  Class {label}: {count} records\")\n",
    "    \n",
    "    # Display the results\n",
    "    print(\"\\nPrediction results:\")\n",
    "    print(results[['proto', 'service', 'state', 'predicted_label', 'attack_probability']].head())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error generating predictions: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33540c08",
   "metadata": {},
   "source": [
    "## Visualize the Results\n",
    "\n",
    "Let's create a visualization to better understand the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61832d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot of probabilities\n",
    "try:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(range(len(results)), results['attack_probability'], \n",
    "                c=results['predicted_label'], cmap='coolwarm', \n",
    "                alpha=0.8, s=100)\n",
    "    plt.axhline(y=0.5, color='gray', linestyle='--', alpha=0.7)\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Probability of Attack')\n",
    "    plt.title('Attack Probabilities for Sample Network Traffic')\n",
    "    plt.colorbar(label='Predicted Class (0: Normal, 1: Attack)')\n",
    "    plt.ylim(-0.05, 1.05)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error visualizing results: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0c6e42",
   "metadata": {},
   "source": [
    "## Test Model Reliability\n",
    "\n",
    "To make sure our model is working consistently, let's run predictions multiple times and check if we get the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ead488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run predictions multiple times to check consistency\n",
    "num_runs = 3\n",
    "all_predictions = []\n",
    "\n",
    "for i in range(num_runs):\n",
    "    predictions = detection_model.predict(sample_data)\n",
    "    all_predictions.append(predictions)\n",
    "\n",
    "# Check if all prediction runs gave the same results\n",
    "predictions_match = all(np.array_equal(all_predictions[0], pred) for pred in all_predictions)\n",
    "\n",
    "if predictions_match:\n",
    "    print(\"✅ Model produces consistent predictions across multiple runs\")\n",
    "else:\n",
    "    print(\"⚠️ Warning: Model produces different predictions across runs\")\n",
    "    \n",
    "    # Show differences if any\n",
    "    for i in range(num_runs-1):\n",
    "        differences = np.sum(all_predictions[i] != all_predictions[i+1])\n",
    "        if differences > 0:\n",
    "            print(f\"Run {i+1} vs Run {i+2}: {differences} differences in predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a314b61",
   "metadata": {},
   "source": [
    "## Analyze Feature Importance\n",
    "\n",
    "Let's see which features are most important for the detection model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33cf4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model has feature_importances_ attribute\n",
    "if hasattr(detection_model.model, 'feature_importances_'):\n",
    "    # Get feature importances\n",
    "    feature_importances = detection_model.model.feature_importances_\n",
    "    feature_names = detection_model.model.feature_names_\n",
    "    \n",
    "    # Create a DataFrame for better visualization\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': feature_importances\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    # Display the top 10 most important features\n",
    "    print(\"Top 10 most important features:\")\n",
    "    print(importance_df.head(10))\n",
    "    \n",
    "    # Plot feature importances\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=importance_df.head(20))\n",
    "    plt.title('Top 20 Most Important Features for Detection')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Model doesn't provide feature importances\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a58f111",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we have successfully tested our `DetectionModel` class and verified that:\n",
    "\n",
    "1. The model initializes correctly and loads the required resources\n",
    "2. It can generate binary predictions (normal vs. attack) for network traffic data\n",
    "3. It produces consistent results across multiple runs\n",
    "4. The predictions and probabilities are reasonable\n",
    "\n",
    "This confirms that our network traffic anomaly detection model is working as expected and is ready for use in a production environment."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
